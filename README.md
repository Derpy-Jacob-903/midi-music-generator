# MIDI Music Generation
![](https://img.shields.io/badge/python-2.7-brightgreen.svg) ![](https://img.shields.io/badge/tensorflow-1.4.0-orange.svg)

Generate music using language modelling approach with LSTM neural networks. MIDI instructions are converted into a sequence of 'words' and the task is to predict the next word in the sequence, given the previous *n* words.

## Requirements
tensorflow==1.4.1
Keras==2.0.8
midi==0.2.3
pygame===1.9.1
pandas==0.22.0
numpy==1.13.1

## Dataset

## Model Description

## Sample Audio
Below are a few music samples generated by this model:

## Acknoledgements
The code for preprocessing the MIDI files has been borrowed from [Tatsuya Hatanaka](https://github.com/tatsuyah/deep-improvisation). 


